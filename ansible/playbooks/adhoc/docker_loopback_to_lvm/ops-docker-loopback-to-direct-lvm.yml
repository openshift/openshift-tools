#!/usr/bin/ansible-playbook
---
# This playbook coverts docker to go from loopback to direct-lvm (the Red Hat recommended way to run docker).
#
# It requires the block device to be already provisioned and attached to the host. This is a generic playbook,
# meant to be used for manual conversion. For AWS specific conversions, use the other playbook in this directory.
#
#  To run:
#   ./ops-docker-loopback-to-direct-lvm.yml -e cli_host=<host to run on> -e cli_docker_device=<path to device>
#
#  Example:
#   ./ops-docker-loopback-to-direct-lvm.yml -e cli_host=twiesttest-master-fd32 -e cli_docker_device=/dev/sdb
#
#  Notes:
#  * This will remove /var/lib/docker!
#  * You may need to re-deploy docker images after this is run (like monitoring)

- name: Fix docker to have a provisioned iops drive
  hosts: "{{ cli_name }}"
  user: root
  connection: ssh
  gather_facts: no
  vars_prompt:
  - name: cli_name
    prompt: Host to convert from loopback to direct LVM
    private: no
  - name: cli_docker_device
    prompt: Docker storage volume device
    default: /dev/xvdb
    private: no

  pre_tasks:
  - fail:
      msg: "This playbook requires {{item}} to be set."
    when: "{{ item }} is not defined or {{ item }} == ''"
    with_items:
    - cli_docker_device
    - cli_name

  - set_fact:
      dss_docker_device: "{{ cli_docker_device }}"

  - name: make sure docker can start
    file:
      path: /var/lib/docker/volumes
      state: directory

  - name: start docker
    service:
      name: docker
      state: started

  - name: Determine if loopback
    shell: docker info | grep 'Data file:.*loop'
    register: loop_device_check
    ignore_errors: yes

  - debug:
      var: loop_device_check

  - name: fail if we don't detect loopback
    fail:
      msg:  loopback not detected! Please investigate manually.
    when: loop_device_check.rc == 1

  - name: stop host monitoring container
    service:
      name: oso-rhel7-host-monitoring
      state: stopped
    ignore_errors: yes

  - name: "check to see if {{ cli_docker_device }} exists"
    command: "test -e {{ cli_docker_device }}"
    register: docker_dev_check
    ignore_errors: yes

  - debug: var=docker_dev_check

  - name: "fail if {{ cli_docker_device }} doesn't exist"
    fail:
      msg: "{{ cli_docker_device }} doesn't exist. Please investigate"
    when: docker_dev_check.rc != 0

  - name: stop docker
    service:
      name: docker
      state: stopped
      enabled: false

  - name: make sure we can remove /var/lib/docker
    command: chattr -i /var/lib/docker/volumes
    ignore_errors: yes

  - name: delete /var/lib/docker
    file:
      state: absent
      path: /var/lib/docker

  - name: load defaults from docker_storage_setup
    include_vars:
      file: ../../../roles/docker_storage_setup/defaults/main.yml

  - name: copy the docker-storage-setup config file
    template:
      # TODO: fix this, this sucks. Right now we can't use that role directly :(
      src: ../../../roles/docker_storage_setup/templates/devicemapper_dss.j2
      dest: /etc/sysconfig/docker-storage-setup
      owner: root
      group: root
      mode: 0664

  - name: docker storage setup
    command: docker-storage-setup
    register: setup_output

  - debug: var=setup_output

  - name: make sure docker can start
    file:
      path: /var/lib/docker/volumes
      state: directory

  - name: start docker
    service:
      name: docker
      state: restarted
      enabled: true

  - name: docker info
    command: docker info
    register: dockerinfo

  - debug: var=dockerinfo
